{"cells":[{"cell_type":"markdown","metadata":{"id":"FDNTc1wFid-1"},"source":["### Student Information\n","Name:唐孟婕\n","\n","Student ID:112062539\n","\n","GitHub ID: jessie1130"]},{"cell_type":"markdown","metadata":{"id":"-BajKEF_id-5"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"rSzgpPbVid-6"},"source":["### Instructions"]},{"cell_type":"markdown","metadata":{"id":"UjbdfsDcid-6"},"source":["1. First: do the **take home** exercises in the [DM2023-Lab1-Master](https://github.com/fjrialdnc0615/DM2023-Lab1-Master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n","\n","\n","2. Second: follow the same process from the [DM2023-Lab1-Master](https://github.com/fjrialdnc0615/DM2023-Lab1-Master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n","    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. You need to combine three labeled datasets into one file for your data preparation part.\n","    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n","\n","\n","3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n","    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n","    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n","    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n","\n","\n","4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n","\n","\n","5. Fifth: It's hard for us to follow if your code is messy, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n","\n","\n","You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fjrialdnc0615/DM2023-Lab1-Master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (October 27th 11:59 pm, Thursday)__. "]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1666241724343,"user":{"displayName":"Kevin Yang","userId":"04518680380941289042"},"user_tz":-480},"id":"IDH6foBIid-9"},"outputs":[],"source":["### Begin Assignment Here"]},{"cell_type":"markdown","metadata":{},"source":["### ** >>> Exercise 1 (5 min): **  \n","In this exercise, please print out the *text* data for the first three samples in the dataset. (See the above code for help)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# obtain the documents containing the categories provided\n","from sklearn.datasets import fetch_20newsgroups\n","\n","twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["From: sd345@city.ac.uk (Michael Collier)\n","Subject: Converting images to HP LaserJet III?\n","Nntp-Posting-Host: hampton\n","Organization: The City University\n","Lines: 14\n","\n","Does anyone know of a good way (standard PC application/PD utility) to\n","convert tif/img/tga files into LaserJet III format.  We would also like to\n","do the same, converting to HPGL (HP plotter) files.\n","\n","Please email any response.\n","\n","Is this the correct group?\n","\n","Thanks in advance.  Michael.\n","-- \n","Michael Collier (Programmer)                 The Computer Unit,\n","Email: M.P.Collier@uk.ac.city                The City University,\n","Tel: 071 477-8000 x3769                      London,\n","Fax: 071 477-8565                            EC1V 0HB.\n","\n","From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\n","Subject: help: Splitting a trimming region along a mesh \n","Organization: University Of Kentucky, Dept. of Math Sciences\n","Lines: 28\n","\n","\n","\n","\tHi,\n","\n","\tI have a problem, I hope some of the 'gurus' can help me solve.\n","\n","\tBackground of the problem:\n","\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \n","\tmapping of a 3d Bezier patch into 2d. The area in this domain\n","\twhich is inside a trimming loop had to be rendered. The trimming\n","\tloop is a set of 2d Bezier curve segments.\n","\tFor the sake of notation: the mesh is made up of cells.\n","\n","\tMy problem is this :\n","\tThe trimming area has to be split up into individual smaller\n","\tcells bounded by the trimming curve segments. If a cell\n","\tis wholly inside the area...then it is output as a whole ,\n","\telse it is trivially rejected. \n","\n","\tDoes any body know how thiss can be done, or is there any algo. \n","\tsomewhere for doing this.\n","\n","\tAny help would be appreciated.\n","\n","\tThanks, \n","\tAni.\n","-- \n","To get irritated is human, to stay cool, divine.\n","\n","From: djohnson@cs.ucsd.edu (Darin Johnson)\n","Subject: Re: harrassed at work, could use some prayers\n","Organization: =CSE Dept., U.C. San Diego\n","Lines: 63\n","\n","(Well, I'll email also, but this may apply to other people, so\n","I'll post also.)\n","\n",">I've been working at this company for eight years in various\n",">engineering jobs.  I'm female.  Yesterday I counted and realized that\n",">on seven different occasions I've been sexually harrassed at this\n",">company.\n","\n",">I dreaded coming back to work today.  What if my boss comes in to ask\n",">me some kind of question...\n","\n","Your boss should be the person bring these problems to.  If he/she\n","does not seem to take any action, keep going up higher and higher.\n","Sexual harrassment does not need to be tolerated, and it can be an\n","enormous emotional support to discuss this with someone and know that\n","they are trying to do something about it.  If you feel you can not\n","discuss this with your boss, perhaps your company has a personnel\n","department that can work for you while preserving your privacy.  Most\n","companies will want to deal with this problem because constant anxiety\n","does seriously affect how effectively employees do their jobs.\n","\n","It is unclear from your letter if you have done this or not.  It is\n","not inconceivable that management remains ignorant of employee\n","problems/strife even after eight years (it's a miracle if they do\n","notice).  Perhaps your manager did not bring to the attention of\n","higher ups?  If the company indeed does seem to want to ignore the\n","entire problem, there may be a state agency willing to fight with\n","you.  (check with a lawyer, a women's resource center, etc to find out)\n","\n","You may also want to discuss this with your paster, priest, husband,\n","etc.  That is, someone you know will not be judgemental and that is\n","supportive, comforting, etc.  This will bring a lot of healing.\n","\n",">So I returned at 11:25, only to find that ever single\n",">person had already left for lunch.  They left at 11:15 or so.  No one\n",">could be bothered to call me at the other building, even though my\n",">number was posted.\n","\n","This happens to a lot of people.  Honest.  I believe it may seem\n","to be due to gross insensitivity because of the feelings you are\n","going through.  People in offices tend to be more insensitive while\n","working than they normally are (maybe it's the hustle or stress or...)\n","I've had this happen to me a lot, often because they didn't realize\n","my car was broken, etc.  Then they will come back and wonder why I\n","didn't want to go (this would tend to make me stop being angry at\n","being ignored and make me laugh).  Once, we went off without our\n","boss, who was paying for the lunch :-)\n","\n",">For this\n",">reason I hope good Mr. Moderator allows me this latest indulgence.\n","\n","Well, if you can't turn to the computer for support, what would\n","we do?  (signs of the computer age :-)\n","\n","In closing, please don't let the hateful actions of a single person\n","harm you.  They are doing it because they are still the playground\n","bully and enjoy seeing the hurt they cause.  And you should not\n","accept the opinions of an imbecile that you are worthless - much\n","wiser people hold you in great esteem.\n","-- \n","Darin Johnson\n","djohnson@ucsd.edu\n","  - Luxury!  In MY day, we had to make do with 5 bytes of swap...\n","\n"]}],"source":["for i in range(3):\n","    print(\"\\n\".join(twenty_train.data[i].split(\"\\n\")))"]},{"cell_type":"markdown","metadata":{},"source":["### ** >>> Exercise 2 (take home):** \n","Experiment with other querying techniques using pandas dataframes. Refer to their [documentation](https://pandas.pydata.org/pandas-docs/stable/indexing.html) for more information. "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>category</th>\n","      <th>category_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7</th>\n","      <td>From: aldridge@netcom.com (Jacquelin Aldridge)...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>From: geb@cs.pitt.edu (Gordon Banks) Subject: ...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>From: libman@hsc.usc.edu (Marlena Libman) Subj...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>From: texx@ossi.com (Robert \"Texx\" Woodworth) ...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>From: rind@enterprise.bih.harvard.edu (David R...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2252</th>\n","      <td>From: roos@Operoni.Helsinki.FI (Christophe Roo...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>2253</th>\n","      <td>From: mhollowa@ic.sunysb.edu (Michael Holloway...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>2254</th>\n","      <td>From: sasghm@theseus.unx.sas.com (Gary Merrill...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>2255</th>\n","      <td>From: Dan Wallach &lt;dwallach@cs.berkeley.edu&gt; S...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>2256</th>\n","      <td>From: dyer@spdcc.com (Steve Dyer) Subject: Re:...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>594 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                   text  category  \\\n","7     From: aldridge@netcom.com (Jacquelin Aldridge)...         2   \n","8     From: geb@cs.pitt.edu (Gordon Banks) Subject: ...         2   \n","9     From: libman@hsc.usc.edu (Marlena Libman) Subj...         2   \n","16    From: texx@ossi.com (Robert \"Texx\" Woodworth) ...         2   \n","28    From: rind@enterprise.bih.harvard.edu (David R...         2   \n","...                                                 ...       ...   \n","2252  From: roos@Operoni.Helsinki.FI (Christophe Roo...         2   \n","2253  From: mhollowa@ic.sunysb.edu (Michael Holloway...         2   \n","2254  From: sasghm@theseus.unx.sas.com (Gary Merrill...         2   \n","2255  From: Dan Wallach <dwallach@cs.berkeley.edu> S...         2   \n","2256  From: dyer@spdcc.com (Steve Dyer) Subject: Re:...         2   \n","\n","     category_name  \n","7          sci.med  \n","8          sci.med  \n","9          sci.med  \n","16         sci.med  \n","28         sci.med  \n","...            ...  \n","2252       sci.med  \n","2253       sci.med  \n","2254       sci.med  \n","2255       sci.med  \n","2256       sci.med  \n","\n","[594 rows x 3 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# my functions\n","from DM2023_Lab1_Master.helpers import data_mining_helpers as dmh\n","\n","# construct dataframe from a list\n","X = pd.DataFrame.from_records(dmh.format_rows(twenty_train), columns= ['text'])\n","X['category'] = twenty_train.target\n","X['category_name'] = X.category.apply(lambda t: dmh.format_labels(t, twenty_train))\n","\n","X.query('category_name == \"sci.med\"')"]},{"cell_type":"markdown","metadata":{},"source":["### ** >>> Exercise 3 (5 min): **  \n","Try to fetch records belonging to the ```sci.med``` category, and query every 10th record. Only show the first 5 records."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>category</th>\n","      <th>category_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7</th>\n","      <td>From: aldridge@netcom.com (Jacquelin Aldridge)...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>From: jimj@contractor.EBay.Sun.COM (Jim Jones)...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>From: jason@ab20.larc.nasa.gov (Jason Austin) ...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>From: rogers@calamari.hi.com (Andrew Rogers) S...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>From: lady@uhunix.uhcc.Hawaii.Edu (Lee Lady) S...</td>\n","      <td>2</td>\n","      <td>sci.med</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  text  category category_name\n","7    From: aldridge@netcom.com (Jacquelin Aldridge)...         2       sci.med\n","49   From: jimj@contractor.EBay.Sun.COM (Jim Jones)...         2       sci.med\n","82   From: jason@ab20.larc.nasa.gov (Jason Austin) ...         2       sci.med\n","118  From: rogers@calamari.hi.com (Andrew Rogers) S...         2       sci.med\n","142  From: lady@uhunix.uhcc.Hawaii.Edu (Lee Lady) S...         2       sci.med"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X[X['category_name'] == 'sci.med'].iloc[::10][0:5]"]},{"cell_type":"markdown","metadata":{},"source":["### >>> **Exercise 4 (5 min):** \n","Let's try something different. Instead of calculating missing values by column let's try to calculate the missing values in every record instead of every column.  \n","$Hint$ : `axis` parameter. Check the documentation for more information."]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["0       (The amoung of missing records is: , 0)\n","1       (The amoung of missing records is: , 0)\n","2       (The amoung of missing records is: , 0)\n","3       (The amoung of missing records is: , 0)\n","4       (The amoung of missing records is: , 0)\n","                         ...                   \n","2252    (The amoung of missing records is: , 0)\n","2253    (The amoung of missing records is: , 0)\n","2254    (The amoung of missing records is: , 0)\n","2255    (The amoung of missing records is: , 0)\n","2256    (The amoung of missing records is: , 0)\n","Length: 2257, dtype: object"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["X.isnull().apply(lambda x: dmh.check_missing_values(x), axis = 1)"]},{"cell_type":"markdown","metadata":{},"source":["### >>> **Exercise 5 (take home)** \n","There is an old saying that goes, \"The devil is in the details.\" When we are working with extremely large data, it's difficult to check records one by one (as we have been doing so far). And also, we don't even know what kind of missing values we are facing. Thus, \"debugging\" skills get sharper as we spend more time solving bugs. Let's focus on a different method to check for missing values and the kinds of missing values you may encounter. It's not easy to check for missing values as you will find out in a minute.\n","\n","Please check the data and the process below, describe what you observe and why it happened.   \n","$Hint$ :  why `.isnull()` didn't work?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>missing_example</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>D</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>E</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>F</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id missing_example\n","0  A             NaN\n","1  B             NaN\n","2  C             NaN\n","3  D            None\n","4  E            None\n","5  F                "]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","\n","NA_dict = [{ 'id': 'A', 'missing_example': np.nan },\n","           { 'id': 'B'                    },\n","           { 'id': 'C', 'missing_example': 'NaN'  },\n","           { 'id': 'D', 'missing_example': 'None' },\n","           { 'id': 'E', 'missing_example':  None  },\n","           { 'id': 'F', 'missing_example': ''     }]\n","\n","NA_df = pd.DataFrame(NA_dict, columns = ['id','missing_example'])\n","NA_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0     True\n","1     True\n","2    False\n","3    False\n","4     True\n","5    False\n","Name: missing_example, dtype: bool"]},"metadata":{},"output_type":"display_data"}],"source":["NA_df['missing_example'].isnull()"]},{"cell_type":"markdown","metadata":{},"source":["Because those data are not null, their datatypes are string. Therefore, they have value."]},{"cell_type":"markdown","metadata":{},"source":["### >>> Exercise 6 (take home):\n","Notice any changes from the `X` dataframe to the `X_sample` dataframe? What are they? Report every change you noticed as compared to the previous state of `X`. Feel free to query and look more closely at the dataframe for these changes."]},{"cell_type":"markdown","metadata":{},"source":["X_sample is formed by random choosing records in X, and it is not in order.\n","Also, if fixing the number of random_state, it would always display the same dataframe."]}],"metadata":{"colab":{"collapsed_sections":["PQPCUbx1ie4R","8qg4up1B_EhD","lC7ymUlG_fai","xtvWLH1x_7nV","bgULadKFBXL-","SZ4rgA1mBir5","9VirxMl6CGN2","yoTS9Vh8ESzB","NGVM3wSjFt7v","bH9BQLSWF9Uf","y8I6L8Z8JGsv","TFIl1hpMJqnv","DobYRQ4FLetu","9pfemrkcLiUG"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":0}
